---
title: "Bayesian Sample Size Estimation for Multilevel Trials"
author: "Ulrich LÃ¶sener"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document: default
  pdf_document: default
---

# Simulation study for the project: Bayesian Sample Size Determination for Multilevel Trials

In this simulation study, I generate multilevel data for N individuals at n timepoints. The within variable is "time" and the between variable "treatment".

First, I call the necessary libraries.

```{r Packages, message=FALSE}
library(tidyr)       # pipes
library(dplyr)       # pipes
library(ggplot2)     # plots
library(lme4)        # fit multilevel model
library(mgcv)        # extracting vcov matrices
library(bain)        # Bayesian estimation
library(MASS)        # multinorm - already included in lme4?
```


```{r Data Generation}

bayesian.SSD <- function(m = 1000, eff.size = .8, BF.thresh = 3, t.points = c(0,1,2,3,4)) {
  
  start <- Sys.time()

  n.steps <- 20  # number of different sample sizes to evaluate
  m <- 100      # number of datasets
  eff.size <- .8 # effect size (Cohen's d): .2 (small), .5 (medium), .8 (large)
  BF.thresh <- 3  # desired Bayes Factor

  t.points <- c(0,1,2,3,4) # time of measurements
  n <- length(t.points)    # number of measurements per subject
  
  prop.bf10.H0 <- numeric(n.steps) # storage for proportions of BFs exceeding a certain threshold
  prop.bf01.H0 <- numeric(n.steps) # storage for proportions of BFs exceeding a certain threshold
  medbf10.H0 <- numeric(n.steps) # storage for median BFs
  medbf01.H0 <- numeric(n.steps) # storage for median BFs
  medbf.1u.H0 <- numeric(n.steps) # storage for median BFs
  medbf.1c.H0 <- numeric(n.steps) # storage for median BFs
  medpmp.a1.H0 <- numeric(n.steps) # storage for median PMPs
  medpmp.b1.H0 <- numeric(n.steps) # storage for median PMPs
  medpmp.c1.H0 <- numeric(n.steps) # storage for median PMPs
  
  prop.bf10.H1 <- numeric(n.steps) # storage for proportions of BFs exceeding a certain threshold
  prop.bf01.H1 <- numeric(n.steps) # storage for proportions of BFs exceeding a certain threshold
  medbf10.H1 <- numeric(n.steps) # storage for median BFs
  medbf01.H1 <- numeric(n.steps) # storage for median BFs
  medbf.1u.H1 <- numeric(n.steps) # storage for median BFs
  medbf.1c.H1 <- numeric(n.steps) # storage for median BFs
  medpmp.a1.H1 <- numeric(n.steps) # storage for median PMPs
  medpmp.b1.H1 <- numeric(n.steps) # storage for median PMPs
  medpmp.c1.H1 <- numeric(n.steps) # storage for median PMPs
  
  ss.seq <- rep(NA, n.steps)
  
  modelsH0 <- rep(list(rep(vector("list", m))),n.steps)
  modelsH1 <- rep(list(rep(vector("list", m))),n.steps)

  set.seed(1234)      # for reproducibility
  #seeds <- vector("list", n.steps) 
  
  sigmasq.u0 <- 1   # variance of individual deviation from treatment intercept 
  sigmasq.u1 <- 1   # variance of individual deviation from treatment slope
  sigma.u0.u1 <- 0  # covariance between sigmasq.u0 and sigmasq.u1. If positive, then individuals with higher(lower) initial values tend to have a higher (lower) rate of change over time.
  sigmasq.e <- .02    # error variance
  
  bf10.H0 <- rep(NA,m) # storage for BFs
  bf01.H0 <- rep(NA,m) # storage for BFs
  bf.1u.H0 <- rep(NA,m) # storage for BFs
  bf.1c.H0 <- rep(NA,m) # storage for BFs
  pmp.a1.H0 <- rep(NA,m) # storage for PMPs
  pmp.b1.H0 <- rep(NA,m) # storage for PMPs
  pmp.c1.H0 <- rep(NA,m) # storage for PMPs
  
  bf10.H1 <- rep(NA,m) # storage for BFs
  bf01.H1 <- rep(NA,m) # storage for BFs
  bf.1u.H1 <- rep(NA,m) # storage for BFs
  bf.1c.H1 <- rep(NA,m) # storage for BFs
  pmp.a1.H1 <- rep(NA,m) # storage for PMPs
  pmp.b1.H1 <- rep(NA,m) # storage for PMPs
  pmp.c1.H1 <- rep(NA,m) # storage for PMPs
  
  for(j in 1:n.steps){
    
    N <- j*4+16      # number of subjects
    ss.seq[j] <- N
    
    # create data vectors
    y <- rep(NA, N)    # data storage
    t <- rep(t.points, N)
    id <- rep(seq_len(N), each=n)
    treat <- as.numeric(as.character(gl(n=2, k=n, length=N*n, labels=c(0,1))))
    dat0 <- data.frame(id, treat, t)
    
    # create population parameters for data generation
    beta0 <- 0 # average y at t0 
    beta1 <- 0 # average increase for x=0
    beta2H0 <- 0 # average difference in slopes between conditions under H0
    beta2H1 <- eff.size * sqrt(sigmasq.u1) # average difference in slopes between conditions under H1
    
      for (i in 1:m) {
      #seeds[[i]] <- .Random.seed
      multinorm <- mvrnorm(n=N, mu=c(0,0), matrix(c(sigmasq.u0, sigma.u0.u1, sigma.u0.u1, sigmasq.u1), nrow=2, ncol=2)) # draw individual deviation from treatment intercept and slope from a multivariate normal distribution with mean 0.
      u0 <- rep(multinorm[,1], each=n)
      u1 <- rep(multinorm[,2], each=n)
      e <- rnorm(N*n, 0, sqrt(sigmasq.e))
      
      yH0 <- beta0 + u0 + beta1*t + beta2H0*treat*t + u1*t + e # data-generating mechanism under H0
      yH1 <- beta0 + u0 + beta1*t + beta2H1*treat*t + u1*t + e # data-generating mechanism under H1
      datH0 <- data.frame(dat0, yH0)
      datH1 <- data.frame(dat0, yH1)

      #inter <- lme(y ~ t + t:treat, random =~ t | id, data = dat, control = lmeControl(opt="optim"))
      modelsH0[[j]][[i]] <- lmer(yH0 ~ t + t:treat + (t | id), data = datH0, control = lmerControl(calc.derivs = F))
      modelsH1[[j]][[i]] <- lmer(yH1 ~ t + t:treat + (t | id), data = datH1, control = lmerControl(calc.derivs = F))

      #if (isSingular(models[[j]][[i]])) {next} # uncomment if singular models are not to be included
      
      estH0 <- modelsH0[[j]][[i]]@beta[3]
      estH1 <- modelsH1[[j]][[i]]@beta[3]
      names(estH0) <- c("t:treat")
      names(estH1) <- c("t:treat")

      sigH0 <- list(as.matrix(vcov(modelsH0[[j]][[i]])[3,3]))
      sigH1 <- list(as.matrix(vcov(modelsH1[[j]][[i]])[3,3]))

      resultH0 <- bain(estH0, hypotheses <- "t:treat>0;t:treat=0", n = N, Sigma = sigH0, group_parameters = 1, joint_parameters = 0) 
      resultH1 <- bain(estH1, hypotheses <- "t:treat>0;t:treat=0", n = N, Sigma = sigH1, group_parameters = 1, joint_parameters = 0) 

      bf10.H0[i] <- resultH0$BFmatrix[1,2]
      bf01.H0[i] <- resultH0$BFmatrix[2,1]
      bf.1u.H0[i] <- resultH0$fit$BF.u[1]
      bf.1c.H0[i] <- resultH0$fit$BF.c[1]
      pmp.a1.H0[i] <- resultH0$fit$PMPa[1]
      pmp.b1.H0[i] <- resultH0$fit$PMPb[1]
      pmp.c1.H0[i] <- resultH0$fit$PMPc[1]
      
      bf10.H1[i] <- resultH1$BFmatrix[1,2]
      bf01.H1[i] <- resultH1$BFmatrix[2,1]
      bf.1u.H1[i] <- resultH1$fit$BF.u[1]
      bf.1c.H1[i] <- resultH1$fit$BF.c[1]
      pmp.a1.H1[i] <- resultH1$fit$PMPa[1]
      pmp.b1.H1[i] <- resultH1$fit$PMPb[1]
      pmp.c1.H1[i] <- resultH1$fit$PMPc[1]
    }
    
    medbf10.H0[j] <- median(bf10.H0, na.rm=T)
    prop.bf10.H0[j] <- length(bf10.H0[bf10.H0>BF.thresh])/m
    prop.bf01.H0[j] <- length(bf01.H0[bf01.H0>BF.thresh])/m
    medbf01.H0[j] <- median(bf01.H0, na.rm=T)
    medbf.1u.H0[j] <- median(bf.1u.H0, na.rm=T)
    medbf.1c.H0[j] <- median(bf.1c.H0, na.rm=T)
    medpmp.a1.H0[j] <- median(pmp.a1.H0, na.rm=T)
    medpmp.b1.H0[j] <- median(pmp.b1.H0, na.rm=T)
    medpmp.c1.H0[j] <- median(pmp.c1.H0, na.rm=T)
    
    medbf10.H1[j] <- median(bf10.H1, na.rm=T)
    prop.bf10.H1[j] <- length(bf10.H1[bf10.H1>BF.thresh])/m
    prop.bf01.H1[j] <- length(bf01.H1[bf01.H1>BF.thresh])/m
    medbf01.H1[j] <- median(bf01.H1, na.rm=T)
    medbf.1u.H1[j] <- median(bf.1u.H1, na.rm=T)
    medbf.1c.H1[j] <- median(bf.1c.H1, na.rm=T)
    medpmp.a1.H1[j] <- median(pmp.a1.H1, na.rm=T)
    medpmp.b1.H1[j] <- median(pmp.b1.H1, na.rm=T)
    medpmp.c1.H1[j] <- median(pmp.c1.H1, na.rm=T)
    
    if (max(prop.bf01.H0)>eff.size & max(prop.bf10.H1)>eff.size) {break}
  }
  
  print(Sys.time() - start) 
  print(N)
  
  par(mfrow=c(2,4))
  plot(x=ss.seq, y=medbf10.H0[1:length(ss.seq)], type="l", xlab="N", ylab="median BF10 under H0")
  plot(x=ss.seq, y=medbf01.H0[1:length(ss.seq)], type="l", xlab="N", ylab="median BF01 under H0")
  plot(x=ss.seq, y=medbf.1u.H0[1:length(ss.seq)], type="l", xlab="N", ylab="median BF unconstr. under H0")
  plot(x=ss.seq, y=medbf.1c.H0[1:length(ss.seq)], type="l", xlab="N", ylab="median BF complement under H0")
  
  plot(x=ss.seq, y=medpmp.a1.H0[1:length(ss.seq)], type="l", xlab="N", ylab="median PMPa under H0")
  plot(x=ss.seq, y=medpmp.b1.H0[1:length(ss.seq)], type="l", xlab="N", ylab="median PMPb under H0")
  plot(x=ss.seq, y=medpmp.c1.H0[1:length(ss.seq)], type="l", xlab="N", ylab="median PMPc under H0")
  plot(x=ss.seq, y=prop.bf01.H0[1:length(ss.seq)], type="l", xlab="N", ylab="proportion of BFs larger 3 under H0")
  abline(h=.8, col="red")
  
  par(mfrow=c(2,4))
  plot(x=ss.seq, y=medbf10.H1[1:length(ss.seq)], type="l", xlab="N", ylab="median BF10 under H1")
  plot(x=ss.seq, y=medbf01.H1[1:length(ss.seq)], type="l", xlab="N", ylab="median BF01 under H1")
  plot(x=ss.seq, y=medbf.1u.H1[1:length(ss.seq)], type="l", xlab="N", ylab="median BF unconstr. under H1")
  plot(x=ss.seq, y=medbf.1c.H1[1:length(ss.seq)], type="l", xlab="N", ylab="median BF complement under H1")
  
  plot(x=ss.seq, y=medpmp.a1.H1[1:length(ss.seq)], type="l", xlab="N", ylab="median PMPa under H1")
  plot(x=ss.seq, y=medpmp.b1.H1[1:length(ss.seq)], type="l", xlab="N", ylab="median PMPb under H1")
  plot(x=ss.seq, y=medpmp.c1.H1[1:length(ss.seq)], type="l", xlab="N", ylab="median PMPc under H1")
  plot(x=ss.seq, y=prop.bf10.H1[1:length(ss.seq)], type="l", xlab="N", ylab="proportion of BFs larger 3 under H1")
  abline(h=eff.size, col="red")
}


```

```{r}
### SINGULARITY DIAGNOSTICS

# marker <- rep(NA, m)
# for(i in 1:m){
#   marker[i] <- ifelse(isSingular(models[[1]][[i]]), 1, 0)
# }
# 
# badmodels <- models[[1]][marker==1]
# goodmodels <- models[[1]][marker==0]
# 
# badest <- rep(NA, length(badmodels))
# badstderr <- rep(NA, length(badmodels))
# for(i in 1:length(badmodels)){
# badest[i] <- badmodels[[i]]@beta[3]
# badstderr[i] <- diag(vcov(badmodels[[i]]))[3]
# }
# 
# goodest <- rep(NA, length(goodmodels))
# goodstderr <- rep(NA, length(goodmodels))
# for(i in 1:length(goodmodels)){
# goodest[i] <- goodmodels[[i]]@beta[3]
# goodstderr[i] <- diag(vcov(goodmodels[[i]]))[3]
# }
# 
# summary(goodest)
# summary(badest)
# summary(goodstderr)
# summary(badstderr)
```


```{r}
# par(mfrow=c(2,2))
# plot(x=ss.seq, y=mbf10[1:length(ss.seq)], type="l", xlab="N", ylab="mean BF12")
# plot(x=ss.seq, y=mbf01[1:length(ss.seq)], type="l", xlab="N", ylab="mean BF21")
# plot(x=ss.seq, y=mbf.u[1:length(ss.seq)], type="l", xlab="N", ylab="mean BF unconstr.")
# plot(x=ss.seq, y=mbf.c[1:length(ss.seq)], type="l", xlab="N", ylab="mean BF complement")

par(mfrow=c(2,2))
plot(x=ss.seq, y=medbf10[1:length(ss.seq)], type="l", xlab="N", ylab="median BF10")
plot(x=ss.seq, y=medbf01[1:length(ss.seq)], type="l", xlab="N", ylab="median BF01")
plot(x=ss.seq, y=medbf.u[1:length(ss.seq)], type="l", xlab="N", ylab="median BF unconstr.")
plot(x=ss.seq, y=medbf.c[1:length(ss.seq)], type="l", xlab="N", ylab="median BF complement")

par(mfrow=c(2,2))
plot(x=ss.seq, y=mpmp.a[1:length(ss.seq)], type="l", xlab="N", ylab="mean PMPa")
plot(x=ss.seq, y=mpmp.b[1:length(ss.seq)], type="l", xlab="N", ylab="mean PMPb")
plot(x=ss.seq, y=mpmp.c[1:length(ss.seq)], type="l", xlab="N", ylab="mean PMPc")
plot(x=ss.seq, y=prop.bf10[1:length(ss.seq)], type="l", xlab="N", ylab="proportion of BFs larger 3")
abline(h=BF.thresh, col="red")

```



```{r PDFs}
pdf(file = "C://Users/losen002/OneDrive - Universiteit Utrecht/Desktop/PhD/BayesianSSD/mBF_N_bet=1.pdf",   
    width = 6, # The width of the plot in inches
    height = 6) # The height of the plot in inches

par(mfrow=c(2,2))
plot(x=seq(10,100,10), y=mbf12, type="l", xlab="N", ylab="mean BF12")
plot(x=seq(10,100,10), y=mbf21, type="l", xlab="N", ylab="mean BF21")
plot(x=seq(10,100,10), y=mbf.u, type="l", xlab="N", ylab="mean BF unconstr.")
plot(x=seq(10,100,10), y=mbf.c, type="l", xlab="N", ylab="mean BF complement")

dev.off()


pdf(file = "C://Users/losen002/OneDrive - Universiteit Utrecht/Desktop/PhD/BayesianSSD/medBF_N_larged.pdf",   
    width = 6, # The width of the plot in inches
    height = 6) # The height of the plot in inches

par(mfrow=c(2,2))
plot(x=ss.seq, y=medbf12[1:length(ss.seq)], type="l", xlab="N", ylab="median BF12")
plot(x=ss.seq, y=medbf21[1:length(ss.seq)], type="l", xlab="N", ylab="median BF21")
plot(x=ss.seq, y=medbf.u[1:length(ss.seq)], type="l", xlab="N", ylab="median BF unconstr.")
plot(x=ss.seq, y=medbf.c[1:length(ss.seq)], type="l", xlab="N", ylab="median BF complement")
mtext("Large effect size (0.2)",side=3,line=-16,outer=TRUE)

dev.off()


pdf(file = "C://Users/losen002/OneDrive - Universiteit Utrecht/Desktop/PhD/BayesianSSD/PMPs_N_larged.pdf",   
    width = 6, # The width of the plot in inches
    height = 6) # The height of the plot in inches

par(mfrow=c(2,2))
plot(x=ss.seq, y=mpmp.a[1:length(ss.seq)], type="l", xlab="N", ylab="mean PMPa")
plot(x=ss.seq, y=mpmp.b[1:length(ss.seq)], type="l", xlab="N", ylab="mean PMPb")
plot(x=ss.seq, y=mpmp.c[1:length(ss.seq)], type="l", xlab="N", ylab="mean PMPc")
plot(x=ss.seq, y=prop.bf12[1:length(ss.seq)], type="l", xlab="N", ylab="Proportion of BFs larger than 3")
abline(h=.8, col="red")
mtext("Large effect size (0.2)",side=3,line=-16,outer=TRUE)

dev.off()


pdf(file = "C://Users/losen002/OneDrive - Universiteit Utrecht/Desktop/PhD/BayesianSSD/Prop.BFs3_N_larged.pdf",   
    width = 6, # The width of the plot in inches
    height = 6) # The height of the plot in inches

plot(x=ss.seq, y=prop.bf12[1:length(ss.seq)], type="l", xlab="N", ylab="proportion of BFs larger 3", main="Large d (0.8)")
abline(h=.8, col="red")

dev.off()

```


The resulting Bayes Factors tell us that $H_1$ is the hypothesis most likely to be true out of the set of considered hypotheses. We therefore conclude that in the treatment group ($X_1$), the symptom level increases more over time compared to the control group ($X_0$).

## Descriptives/plots

```{r Descriptives, echo=F}
# plot individual trajectories
ggplot(data = dat, aes(x = t, y = y, group = id, color = as.factor(treat))) + geom_line()

boxplot(formula = y ~ treat, data = dat) # in a boxplot
```

As can be seen from the figure, individuals differ in their intercept and slope. Subjects in the treatment group ($X_1$) seem to have systematically higher slopes as compared to those in the control group ($X_0$), suggesting an interaction effect between time and treatment. Also, the variability of y scores seems to increase over time, rendering the assumption of compound symmetry untenable. 


```{r Plots, echo=F}
# one line for everyone
ggplot(data = dat, aes(x = t, y = y), color = treat) + 
  geom_jitter(aes(color = treat), width = .1, height = 0) + 
  geom_smooth(method = "lm", formula = 'y ~ x')
# base
p <- ggplot(data = dat, aes(x = t, y = y, group = id, color = treat)) + geom_jitter(width = .1, height = 0)
# different lines for treat
p  + geom_smooth(group = 0, method = "lm", data = subset(dat, dat$treat == 0), formula = 'y ~ x') + geom_smooth(group = 0, method = "lm", data = subset(dat, dat$treat == 1), formula = 'y ~ x')

```

## Intercept only model

```{r Intercept only}
int.only <- lmer(y ~ 1 + (1 | id), data = dat)
summary(int.only) 
logLik(int.only)           
performance::icc(int.only) 
p + geom_smooth(method = "lm", formula = y ~ 1, se = F)
```

--------------------------------------------------------------------------------

## Appendix: In-between models

### Level 1 predictor: time

```{r Lvl 1}
lvl1 <- lmer(y ~ time + (1 | id), data = dat)
summary(lvl1)
logLik(lvl1)           
anova(int.only, lvl1)  
performance::icc(lvl1) 
```


### Level 2 predictor: treat

```{r Lvl 2}
lvl2 <- lmer(y ~ time + treat + (1 | id), data = dat)
summary(lvl2)
logLik(lvl2)           # -1063.76 (df=5) - better fit compared to lvl1 predictor only
anova(lvl1, lvl2)      # likelihood ratio test significant
performance::icc(lvl2) # 0.044
vcov.lmerMod(lvl2)
```

### Random slope for time

```{r Random slope}
rand.slop <- lmer(y ~ time + treat + (1 + time | id), data = dat)
summary(rand.slop)
logLik(rand.slop) 
anova(lvl2, rand.slop)
performance::icc(rand.slop)
```
