---
title: "Bayesian Sample Size Estimation for Multilevel Trials"
author: "Ulrich LÃ¶sener"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document: default
  pdf_document: default
---

# Simulation study for the project: Bayesian Sample Size Determination for Multilevel Trials

In this simulation study, I generate multilevel data for N individuals at n timepoints. The within variable is "time" and the between variable "treatment".

First, I call the necessary libraries.

```{r Packages, message=FALSE}
library(tidyr)       # pipes
library(dplyr)       # pipes
library(ggplot2)     # plots
library(lme4)        # fit multilevel model
library(mgcv)        # extracting vcov matrices
library(bain)        # Bayesian estimation
library(MASS)        # multinorm - already included in lme4?
```


```{r Data Generation}

bayesian.SSD <- function(true.hyp = 1, n.steps = 20, m = 1000, eff.size = .8, t.points = c(0,1,2,3,4)) {
  
  start <- Sys.time()

  true.hyp <- 1 # which hypothesis is true? H0: b=0; H1: b>0
  n.steps <- 20 # number of different sample sizes to evaluate
  m <- 1000 # number of datasets
  eff.size <- .8  # effect size (Cohen's d): .2 (small), .5 (medium), .8 (large)

  t.points <- c(0,1,2,3,4) # time of measurements
  n <- length(t.points)    # number of measurements per subject
  
  mbf10 <- numeric(n.steps) # storage for mean BFs 
  mbf01 <- numeric(n.steps) # storage for mean BFs 
  mbf.u <- numeric(n.steps) # storage for mean BFs 
  mbf.c <- numeric(n.steps) # storage for mean BFs
  mpmp.a <- numeric(n.steps) # storage for mean PMPs
  mpmp.b <- numeric(n.steps) # storage for mean PMPs
  mpmp.c <- numeric(n.steps) # storage for mean PMPs
  
  quantbf10 <- numeric(n.steps) # storage for quantiles in vectors containing BFs
  prop.bf10 <- numeric(n.steps) # storage for proportions of BFs exceeding a certain threshold
  prop.bf01 <- numeric(n.steps) # storage for proportions of BFs exceeding a certain threshold
  medbf10 <- numeric(n.steps) # storage for median BFs
  medbf01 <- numeric(n.steps) # storage for median BFs
  medbf.u <- numeric(n.steps) # storage for median BFs
  medbf.c <- numeric(n.steps) # storage for median BFs
  medpmp.a <- numeric(n.steps) # storage for median PMPs
  medpmp.b <- numeric(n.steps) # storage for median PMPs
  medpmp.c <- numeric(n.steps) # storage for median PMPs
  
  ss.seq <- rep(NA, n.steps)
  
  models <- rep(list(rep(vector("list", m))),n.steps)
  
  set.seed(1234)      # for reproducibility
  #seeds <- vector("list", n.steps) 
  
  
  
  sigmasq.u0 <- 1   # variance of individual deviation from treatment intercept 
  sigmasq.u1 <- 1   # variance of individual deviation from treatment slope
  sigma.u0.u1 <- 0  # covariance between sigmasq.u0 and sigmasq.u1. If positive, then individuals with higher(lower) initial values tend to have a higher (lower) rate of change over time.
  sigmasq.e <- 1    # error variance
  
  bf10 <- rep(NA,m) # storage for BFs
  bf01 <- rep(NA,m) # storage for BFs
  bf.u <- rep(NA,m) # storage for BFs
  bf.c <- rep(NA,m) # storage for BFs
  pmp.a <- rep(NA,m) # storage for PMPs
  pmp.b <- rep(NA,m) # storage for PMPs
  pmp.c <- rep(NA,m) # storage for PMPs
  
  for(j in 1:n.steps){
    
    N <- j*4+16        # number of subjects
    ss.seq[j] <- N
    
    # create data vectors
    y <- rep(NA, N)    # data storage
    t <- rep(t.points, N)
    id <- rep(seq_len(N), each=n)
    treat <- rep(c(rep(0,n), rep(1,n)), N/2) # use gl instead?
    dat0 <- data.frame(id, treat, t)
    
    beta0 <- rep(0, N*n) # average y at t0 
    beta1 <- rep(0, N*n) # average increase for x=0
    beta2 <- ifelse(true.hyp==1, rep(eff.size*sqrt(sigmasq.u1), N*n), rep(0, N*n)) # average difference in slopes between conditions
    
      for (i in 1:m) {
      #seeds[[i]] <- .Random.seed
      multinorm <- mvrnorm(n=N, mu=c(0,0), matrix(c(sigmasq.u0, sigma.u0.u1, sigma.u0.u1, sigmasq.u1), nrow=2, ncol=2)) # draw individual deviation from treatment intercept and slope from a multivariate normal distribution with mean 0.
      u0 <- rep(multinorm[,1], each=n)
      u1 <- rep(multinorm[,2], each=n)
      e <- rnorm(N*n, 0, sqrt(sigmasq.e))
      
      y <- beta0 + u0 + beta1*t + beta2*treat*t + u1*t + e
      dat <- data.frame(dat0, y)
      
      #inter <- lme(y ~ t + t:treat, random =~ t | id, data = dat, control = lmeControl(opt="optim"))
      models[[j]][[i]] <- lmer(y ~ t + t:treat + (t | id), data = dat, control = lmerControl(calc.derivs = F))
      #if (isSingular(models[[j]][[i]])) {next} # uncomment if singular models are not to be included
      
      est <- models[[j]][[i]]@beta[3]
      names(est) <- c("t:treat")
      sig <- list(as.matrix(vcov(models[[j]][[i]])[3,3]))
      
      result <- bain(est, hypotheses <- "t:treat>0;t:treat=0", n = N, Sigma = sig, group_parameters = 1, joint_parameters = 0) # double check whether group and joint pars are correct
      
      bf10[i] <- result$BFmatrix[1,2]
      bf01[i] <- result$BFmatrix[2,1]
      bf.u[i] <- result$fit$BF.u[1]
      bf.c[i] <- result$fit$BF.c[1]
      pmp.a[i] <- result$fit$PMPa[1]
      pmp.b[i] <- result$fit$PMPb[1]
      pmp.c[i] <- result$fit$PMPc[1]
    }
     
    mbf10[j] <- mean(bf10, na.rm=T)
    mbf01[j] <- mean(bf01, na.rm=T)
    mbf.u[j] <- mean(bf.u, na.rm=T)
    mbf.c[j] <- mean(bf.c, na.rm=T)
    mpmp.a[j] <- mean(pmp.a, na.rm=T)
    mpmp.b[j] <- mean(pmp.b, na.rm=T)
    mpmp.c[j] <- mean(pmp.c, na.rm=T)
    
    medbf10[j] <- median(bf10, na.rm=T)
    quantbf10[j] <- quantile(bf10, probs=0.2, na.rm=T)
    prop.bf10[j] <- length(bf10[bf10>3])/m
    prop.bf01[j] <- length(bf01[bf01>3])/m
    medbf01[j] <- median(bf01, na.rm=T)
    medbf.u[j] <- median(bf.u, na.rm=T)
    medbf.c[j] <- median(bf.c, na.rm=T)
    medpmp.a[j] <- median(pmp.a, na.rm=T)
    medpmp.b[j] <- median(pmp.b, na.rm=T)
    medpmp.c[j] <- median(pmp.c, na.rm=T)
    
    if (max(prop.bf10)>.8) {break}
  }
  
  print(Sys.time() - start) 
  print(N)
  
  par(mfrow=c(2,4))
  plot(x=ss.seq, y=medbf10[1:length(ss.seq)], type="l", xlab="N", ylab="median BF10")
  plot(x=ss.seq, y=medbf01[1:length(ss.seq)], type="l", xlab="N", ylab="median BF01")
  plot(x=ss.seq, y=medbf.u[1:length(ss.seq)], type="l", xlab="N", ylab="median BF unconstr.")
  plot(x=ss.seq, y=medbf.c[1:length(ss.seq)], type="l", xlab="N", ylab="median BF complement")
  
  plot(x=ss.seq, y=mpmp.a[1:length(ss.seq)], type="l", xlab="N", ylab="mean PMPa")
  plot(x=ss.seq, y=mpmp.b[1:length(ss.seq)], type="l", xlab="N", ylab="mean PMPb")
  plot(x=ss.seq, y=mpmp.c[1:length(ss.seq)], type="l", xlab="N", ylab="mean PMPc")
  plot(x=ss.seq, y=prop.bf10[1:length(ss.seq)], type="l", xlab="N", ylab="proportion of BFs larger 3")
  abline(h=.8, col="red")
}


```

```{r}
### SINGULARITY DIAGNOSTICS

# marker <- rep(NA, m)
# for(i in 1:m){
#   marker[i] <- ifelse(isSingular(models[[1]][[i]]), 1, 0)
# }
# 
# badmodels <- models[[1]][marker==1]
# goodmodels <- models[[1]][marker==0]
# 
# badest <- rep(NA, length(badmodels))
# badstderr <- rep(NA, length(badmodels))
# for(i in 1:length(badmodels)){
# badest[i] <- badmodels[[i]]@beta[3]
# badstderr[i] <- diag(vcov(badmodels[[i]]))[3]
# }
# 
# goodest <- rep(NA, length(goodmodels))
# goodstderr <- rep(NA, length(goodmodels))
# for(i in 1:length(goodmodels)){
# goodest[i] <- goodmodels[[i]]@beta[3]
# goodstderr[i] <- diag(vcov(goodmodels[[i]]))[3]
# }
# 
# summary(goodest)
# summary(badest)
# summary(goodstderr)
# summary(badstderr)
```


```{r}
# par(mfrow=c(2,2))
# plot(x=ss.seq, y=mbf10[1:length(ss.seq)], type="l", xlab="N", ylab="mean BF12")
# plot(x=ss.seq, y=mbf01[1:length(ss.seq)], type="l", xlab="N", ylab="mean BF21")
# plot(x=ss.seq, y=mbf.u[1:length(ss.seq)], type="l", xlab="N", ylab="mean BF unconstr.")
# plot(x=ss.seq, y=mbf.c[1:length(ss.seq)], type="l", xlab="N", ylab="mean BF complement")

par(mfrow=c(2,2))
plot(x=ss.seq, y=medbf10[1:length(ss.seq)], type="l", xlab="N", ylab="median BF10")
plot(x=ss.seq, y=medbf01[1:length(ss.seq)], type="l", xlab="N", ylab="median BF01")
plot(x=ss.seq, y=medbf.u[1:length(ss.seq)], type="l", xlab="N", ylab="median BF unconstr.")
plot(x=ss.seq, y=medbf.c[1:length(ss.seq)], type="l", xlab="N", ylab="median BF complement")

par(mfrow=c(2,2))
plot(x=ss.seq, y=mpmp.a[1:length(ss.seq)], type="l", xlab="N", ylab="mean PMPa")
plot(x=ss.seq, y=mpmp.b[1:length(ss.seq)], type="l", xlab="N", ylab="mean PMPb")
plot(x=ss.seq, y=mpmp.c[1:length(ss.seq)], type="l", xlab="N", ylab="mean PMPc")
plot(x=ss.seq, y=prop.bf10[1:length(ss.seq)], type="l", xlab="N", ylab="proportion of BFs larger 3")
abline(h=.8, col="red")

```



```{r PDFs}
pdf(file = "C://Users/losen002/OneDrive - Universiteit Utrecht/Desktop/PhD/BayesianSSD/mBF_N_bet=1.pdf",   
    width = 6, # The width of the plot in inches
    height = 6) # The height of the plot in inches

par(mfrow=c(2,2))
plot(x=seq(10,100,10), y=mbf12, type="l", xlab="N", ylab="mean BF12")
plot(x=seq(10,100,10), y=mbf21, type="l", xlab="N", ylab="mean BF21")
plot(x=seq(10,100,10), y=mbf.u, type="l", xlab="N", ylab="mean BF unconstr.")
plot(x=seq(10,100,10), y=mbf.c, type="l", xlab="N", ylab="mean BF complement")

dev.off()


pdf(file = "C://Users/losen002/OneDrive - Universiteit Utrecht/Desktop/PhD/BayesianSSD/medBF_N_larged.pdf",   
    width = 6, # The width of the plot in inches
    height = 6) # The height of the plot in inches

par(mfrow=c(2,2))
plot(x=ss.seq, y=medbf12[1:length(ss.seq)], type="l", xlab="N", ylab="median BF12")
plot(x=ss.seq, y=medbf21[1:length(ss.seq)], type="l", xlab="N", ylab="median BF21")
plot(x=ss.seq, y=medbf.u[1:length(ss.seq)], type="l", xlab="N", ylab="median BF unconstr.")
plot(x=ss.seq, y=medbf.c[1:length(ss.seq)], type="l", xlab="N", ylab="median BF complement")
mtext("Large effect size (0.2)",side=3,line=-16,outer=TRUE)

dev.off()


pdf(file = "C://Users/losen002/OneDrive - Universiteit Utrecht/Desktop/PhD/BayesianSSD/PMPs_N_larged.pdf",   
    width = 6, # The width of the plot in inches
    height = 6) # The height of the plot in inches

par(mfrow=c(2,2))
plot(x=ss.seq, y=mpmp.a[1:length(ss.seq)], type="l", xlab="N", ylab="mean PMPa")
plot(x=ss.seq, y=mpmp.b[1:length(ss.seq)], type="l", xlab="N", ylab="mean PMPb")
plot(x=ss.seq, y=mpmp.c[1:length(ss.seq)], type="l", xlab="N", ylab="mean PMPc")
plot(x=ss.seq, y=prop.bf12[1:length(ss.seq)], type="l", xlab="N", ylab="Proportion of BFs larger than 3")
abline(h=.8, col="red")
mtext("Large effect size (0.2)",side=3,line=-16,outer=TRUE)

dev.off()


pdf(file = "C://Users/losen002/OneDrive - Universiteit Utrecht/Desktop/PhD/BayesianSSD/Prop.BFs3_N_larged.pdf",   
    width = 6, # The width of the plot in inches
    height = 6) # The height of the plot in inches

plot(x=ss.seq, y=prop.bf12[1:length(ss.seq)], type="l", xlab="N", ylab="proportion of BFs larger 3", main="Large d (0.8)")
abline(h=.8, col="red")

dev.off()

```


The resulting Bayes Factors tell us that $H_1$ is the hypothesis most likely to be true out of the set of considered hypotheses. We therefore conclude that in the treatment group ($X_1$), the symptom level increases more over time compared to the control group ($X_0$).

## Descriptives/plots

```{r Descriptives, echo=F}
# plot individual trajectories
ggplot(data = dat, aes(x = t, y = y, group = id, color = as.factor(treat))) + geom_line()

boxplot(formula = y ~ treat, data = dat) # in a boxplot
```

As can be seen from the figure, individuals differ in their intercept and slope. Subjects in the treatment group ($X_1$) seem to have systematically higher slopes as compared to those in the control group ($X_0$), suggesting an interaction effect between time and treatment. Also, the variability of y scores seems to increase over time, rendering the assumption of compound symmetry untenable. 


```{r Plots, echo=F}
# one line for everyone
ggplot(data = dat, aes(x = t, y = y), color = treat) + 
  geom_jitter(aes(color = treat), width = .1, height = 0) + 
  geom_smooth(method = "lm", formula = 'y ~ x')
# base
p <- ggplot(data = dat, aes(x = t, y = y, group = id, color = treat)) + geom_jitter(width = .1, height = 0)
# different lines for treat
p  + geom_smooth(group = 0, method = "lm", data = subset(dat, dat$treat == 0), formula = 'y ~ x') + geom_smooth(group = 0, method = "lm", data = subset(dat, dat$treat == 1), formula = 'y ~ x')

```

## Intercept only model

```{r Intercept only}
int.only <- lmer(y ~ 1 + (1 | id), data = dat)
summary(int.only) 
logLik(int.only)           
performance::icc(int.only) 
p + geom_smooth(method = "lm", formula = y ~ 1, se = F)
```

--------------------------------------------------------------------------------

## Appendix: In-between models

### Level 1 predictor: time

```{r Lvl 1}
lvl1 <- lmer(y ~ time + (1 | id), data = dat)
summary(lvl1)
logLik(lvl1)           
anova(int.only, lvl1)  
performance::icc(lvl1) 
```


### Level 2 predictor: treat

```{r Lvl 2}
lvl2 <- lmer(y ~ time + treat + (1 | id), data = dat)
summary(lvl2)
logLik(lvl2)           # -1063.76 (df=5) - better fit compared to lvl1 predictor only
anova(lvl1, lvl2)      # likelihood ratio test significant
performance::icc(lvl2) # 0.044
vcov.lmerMod(lvl2)
```

### Random slope for time

```{r Random slope}
rand.slop <- lmer(y ~ time + treat + (1 + time | id), data = dat)
summary(rand.slop)
logLik(rand.slop) 
anova(lvl2, rand.slop)
performance::icc(rand.slop)
```
