---
title: "Bayesian Sample Size Estimation for Multilevel Trials"
author: "Ulrich LÃ¶sener"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document: default
  pdf_document: default
---


```{r Packages, message=FALSE}
library(tidyr)       # pipes
library(dplyr)       # pipes
library(ggplot2)     # plots
library(lme4)        # fit multilevel model
library(mgcv)        # extracting vcov matrices
library(bain)        # Bayesian estimation
library(MASS)        # multinorm - already included in lme4?
library(latex2exp)   # latex notation in plots
```


SSD Function
```{r Function SSD}
SSD <- function(m=10000, t.points=c(1,2,3,4,5), var.u0=0, var.u1=.1, var.e=.02, eff.size=.8, BFthres=3, eta=.8){
  
  source("fct_data_generation.R")
  start <- Sys.time()
  
  N <- 30            # initial N
  condition <- FALSE # condition initially false
  i <- 1             # iteration number
  
  medBF10.H1 <- vector("list", 100)
  medBF1c.H1 <- vector("list", 100)
  medBF01.H0 <- vector("list", 100)
  medBF0c.H0 <- vector("list", 100)
  prop.BF01.H0 <- vector("list", 100)
  prop.BF10.H1 <- vector("list", 100)
  mean.log.BF01.H0 <- vector("list", 100)
  mean.log.BF10.H1 <- vector("list", 100)
  
  while (condition==F) {
    
    N <- N+2
    results <- dat.gen(m=m, N=N, t.points=t.points, var.u0=var.u0, var.u1=var.u1, var.e=var.e, eff.size=eff.size, BFthres=BFthres)
    
    medBF01.H0[[i]] <- results$Median_BF0
    medBF10.H1[[i]] <- results$Median_BF1
    prop.BF01.H0[[i]] <- results$Prop_BF0
    prop.BF10.H1[[i]] <- results$Prop_BF1
    mean.log.BF01.H0[[i]] <- results$Meanlog_BF0
    mean.log.BF10.H1[[i]] <- results$Meanlog_BF1

    # condition met?
    ifelse(prop.BF01.H0[[i]]>eta & prop.BF10.H1[[i]]>eta, condition <- TRUE, condition <- FALSE)
    print(list(N, prop.BF10.H1[[i]]))
    i <- i+1
  }

  measures <- cbind(medBF01.H0,medBF10.H1, prop.BF01.H0, prop.BF10.H1, mean.log.BF01.H0, mean.log.BF10.H1, N)
  print(Sys.time() - start)
  return(measures[i-1,])

}
```


```{r Function SSD}





rat <- rep(list(vector("list", 5)), 9)

for(i in 1:9){
  rat[i][[1]] <- SSD(var.u1 = i/10, var.e = 1 - i/10)
}

rats

rat.medBF01.H0 <- rep(NA, 9)
rat.medBF10.H1 <- rep(NA, 9)
rat.N <- rep(NA, 9)
  
  
for(i in 1:9){
rat.medBF01.H0[i] <- rat[[i]][1]
rat.medBF10.H1[i] <- rat[[i]][2]
rat.N[i] <- rat[[i]][5]
}

d <- as.data.frame(cbind(as.numeric(rat.medBF01.H0), as.numeric(rat.medBF10.H1), as.numeric(rat.N), rats))
colnames(d) <- c("medBF01.H0", "medBF10.H1", "N", "ratio")

x <- seq(32, 74, by=2)

pdf(file = "C://Users/losen002/OneDrive - Universiteit Utrecht/Desktop/PhD/BayesianSSD/medBF10.H1.pdf", width = 6, height = 6)
ggplot() + geom_line(aes(y=unlist(medBF10.H1), x=x), linewidth=1) + xlab("N") + ylab("Median BF10 under H1") 
# + geom_hline(yintercept=.8, col="red", linetype="dashed") 


dev.off()

```


```{r}
library(Rcpp)
cppFunction('NumericVector SSDc(int m, NumericVector tpoints, double var.u1, double var.e, double eff.size, double BFthres, double eta){
  int N = 30;
  double power = 0;
  Function dat.gen.cpp("dat.gen");
  
  while(power<.80){
    N = N+2;
    NumericVector results = dat.gen.cpp(m=m, N=N, t.points=t.points, ar.u0=var.u0, var.u1=var.u1, var.e=var.e, eff.size=eff.size, BFthres=BFthres);
    
    
  }
}')




```



```{r Plots}
# increase in Prop BF larger 3


b$N <- as.numeric(b$N)
b$prop.BF10.H1 <- as.numeric(b$prop.BF10.H1)



ggplot(data=b, aes(x=N, y=prop.BF10.H1), linewidth=1.5) + 
  geom_line() +
  geom_hline(yintercept=.8, col="red", linetype="dashed") +
  labs(x="Proportion of BF01 larger than 3") 



```




Binary Algorithm
```{r Function SSD Binary}

SSD.binary <- function(m=100, t.points=c(1,2,3,4,5), var.u0=.0333, var.u1=.1, var.e=.0262, eff.size=.8, BFthres=3){
  source("fct_data_generation.R")
  
  start <- Sys.time()
  eta <- .8          # desired power
  N.current <- 30    # initial N
  N.min <- 20
  N.max <- 1000

  while (N.current!=N.min+1) {
    
    N.current <- round((N.min + N.max)/2, digits = 0)

    results <- dat.gen(m=m, N=N.current, t.points=t.points, var.u0=var.u0, var.u1=var.u1, var.e=var.e, eff.size=eff.size, BFthres=BFthres)
    # condition met?
    ifelse(results$Prop_BF0>eta & results$Prop_BF1>eta, condition <- TRUE, condition <- FALSE)
    ifelse(condition==FALSE, N.min <- N.current, N.max <- N.current)
    print(N.current)
    
  }
  print(Sys.time() - start) 

}

```
  


```{r}
df.prop.bf10.H1 <- as.data.frame(cbind(prop.bf10.H1[1:length(na.exclude(ss.seq))], na.exclude(ss.seq)))
colnames(df.prop.bf10.H1) <- c("prop.bf", "N")

# increase in proportion of BFs larger than BFthres
pdf(file = "C://Users/losen002/OneDrive - Universiteit Utrecht/Desktop/PhD/BayesianSSD/Prop.BF.medium.pdf", width = 6, height = 6)
ggplot(data=df.prop.bf10.H1, aes(x=N, y=prop.bf), linewidth=1.5) + 
  geom_line() +
  geom_hline(yintercept=eta, col="red", linetype="dashed") +
  labs(x="Proportion of BF01 larger than 3") 
dev.off()

# Sampling distribution of BFs for N
  
#bf10.H1.trim <- bf10.H1 #[bf10.H1<=quantile(bf10.H1, probs = .99)]
df.prop.bfs <- data.frame(c(bf10.H1, bf01.H0), rep(c("1","0"), each=m))
colnames(df.prop.bfs) <- c("BF", "hyp")
```

```{r}
# H0
p0 <- ggplot() + geom_density(aes(x=bf01.H0), linewidth=1) + 
  xlim(-3, 220) + 
  labs(title = "Sampling Distribution of BF01 under H0 with N = 20", y="density", x="BF01") 

dpb0 <- ggplot_build(p0)

p0 + geom_area(data=data.frame(x=dpb0$data[[1]]$x[dpb0$data[[1]]$x>3], y=dpb0$data[[1]]$y[dpb0$data[[1]]$x>3]), aes(x=x, y=y), fill="grey") +
    annotate("text", x=c(-3,25), y=c(.015,0.005), label=c(TeX("$BF_{thresh} = 3$"), TeX("$\\eta = .80$")), angle=c(90,0)) +
    geom_vline(xintercept=3, linetype=2, color="red", linewidth=1)

# H1
p1 <- ggplot() + geom_density(aes(x=bf10.H1), linewidth=1) + 
  xlim(-3, 220) + 
  labs(title = "Sampling Distribution of BF10 under H1 with N = 116", y="density", x="BF10") 

dpb1 <- ggplot_build(p1)

p1 + geom_area(data=data.frame(x=dpb1$data[[1]]$x[dpb1$data[[1]]$x>3], y=dpb1$data[[1]]$y[dpb1$data[[1]]$x>3]), aes(x=x, y=y), fill="grey") +
    annotate("text", x=c(-3,25), y=c(.01,0.0025), label=c(TeX("$BF_{thresh} = 3$"), TeX("$\\eta = .80$")), angle=c(90,0)) +
    geom_vline(xintercept=3, linetype=2, color="red", linewidth=1) 
```



# H0
bf01.H0.trim <- bf01.H0 #bf01.H0[bf01.H0<=quantile(bf01.H0, probs = .85)]
  
  plot(density(bf01.H0.trim), xlim=range(0:50))
  polygon(c(density(bf01.H0.trim)$x[density(bf01.H0.trim)$x >= 3 ], 3),
        c(density(bf01.H0.trim)$y[density(bf01.H0.trim)$x >= 3 ], 0),
        col = "slateblue1",
        border = 1)

p0 <- ggplot() + geom_density(aes(x=bf01.H0.trim), size=1) + 
  xlim(0, 50) + 
  geom_vline(xintercept=3, linetype=2, color="red") +
  annotate("text", x=2, y=.02, label="BFthresh=3", angle=90) +
  labs(title = TeX(r"(Sampling Distribution of $BF_{01}$ under $H_0$ for $N=20$)"), y="density", x=TeX("$BF_{01}$"))

dpb0 <- ggplot_build(p0)

p0 + geom_area(data=data.frame(x=dpb0$data[[1]]$x[dpb0$data[[1]]$x>3],
                       y=dpb0$data[[1]]$y[dpb0$data[[1]]$x>3]),
            aes(x=x, y=y), fill="grey")

```{r}

# both

pdf(file = "C://Users/losen002/OneDrive - Universiteit Utrecht/Desktop/PhD/BayesianSSD/SampDistH1.pdf", width = 6, height = 6)

p + geom_area(data=data.frame(x=dpb$data[[1]]$x[dpb$data[[1]]$x>3],
                       y=dpb$data[[1]]$y[dpb$data[[1]]$x>3]),
            aes(x=x, y=y), fill="grey")
dev.off()

pdf(file = "C://Users/losen002/OneDrive - Universiteit Utrecht/Desktop/PhD/BayesianSSD/SampDistH0.pdf", width = 6, height = 6)
p0 + geom_area(data=data.frame(x=dpb0$data[[1]]$x[dpb0$data[[1]]$x>3],
                       y=dpb0$data[[1]]$y[dpb0$data[[1]]$x>3]),
            aes(x=x, y=y), fill="grey")
dev.off()

# StatAreaUnderDensity <- ggproto(
#   "StatAreaUnderDensity", Stat,
#   required_aes = "x",
#   compute_group = function(data, scales, xlim = NULL, n = 50) {
#     fun <- approxfun(density(data$x))
#     StatFunction$compute_group(data, scales, fun = fun, xlim = xlim, n = n)
#   }
# )
# 
# stat_aud <- function(mapping = NULL, data = NULL, geom = "area",
#                     position = "identity", na.rm = FALSE, show.legend = NA, 
#                     inherit.aes = TRUE, n = 50, xlim=NULL,  
#                     ...) {
#   layer(
#     stat = StatAreaUnderDensity, data = data, mapping = mapping, geom = geom, 
#     position = position, show.legend = show.legend, inherit.aes = inherit.aes,
#     params = list(xlim = xlim, n = n, ...))
# }

```


```{r}
### SINGULARITY DIAGNOSTICS

marker <- rep(NA, m)
for(i in 1:m){
  marker[i] <- ifelse(isSingular(modelsH0[[1]][[i]]), 1, 0)
}

badmodels <- modelsH0[[1]][marker==1]
goodmodels <- modelsH0[[1]][marker==0]

badest <- rep(NA, length(badmodels))
badstderr <- rep(NA, length(badmodels))
for(i in 1:length(badmodels)){
badest[i] <- badmodels[[i]]@beta[3]
badstderr[i] <- diag(vcov(badmodels[[i]]))[3]
}

goodest <- rep(NA, length(goodmodels))
goodstderr <- rep(NA, length(goodmodels))
for(i in 1:length(goodmodels)){
goodest[i] <- goodmodels[[i]]@beta[3]
goodstderr[i] <- diag(vcov(goodmodels[[i]]))[3]
}

length(goodmodels)
length(badmodels)

summary(goodest)
summary(badest)
summary(goodstderr)
summary(badstderr)
```



```{r PDFs}

pdf(file = "C://Users/losen002/OneDrive - Universiteit Utrecht/Desktop/PhD/BayesianSSD/BF_PMP_H0.pdf",   
    width = 6, # The width of the plot in inches
    height = 6) # The height of the plot in inches

  par(mfrow=c(2,4))
  plot(x=ss.seq, y=medbf10.H0[1:length(ss.seq)], type="l", xlab="N", ylab="median BF10 under H0")
  plot(x=ss.seq, y=medbf01.H0[1:length(ss.seq)], type="l", xlab="N", ylab="median BF01 under H0")
  plot(x=ss.seq, y=medbf.1u.H0[1:length(ss.seq)], type="l", xlab="N", ylab="median BF unconstr. under H0")
  plot(x=ss.seq, y=medbf.1c.H0[1:length(ss.seq)], type="l", xlab="N", ylab="median BF complement under H0")
  
  plot(x=ss.seq, y=medpmp.a1.H0[1:length(ss.seq)], type="l", xlab="N", ylab="median PMPa under H0")
  plot(x=ss.seq, y=medpmp.b1.H0[1:length(ss.seq)], type="l", xlab="N", ylab="median PMPb under H0")
  plot(x=ss.seq, y=medpmp.c1.H0[1:length(ss.seq)], type="l", xlab="N", ylab="median PMPc under H0")
  plot(x=ss.seq, y=prop.bf01.H0[1:length(ss.seq)], type="l", xlab="N", ylab="proportion of BFs larger 3 under H0")
  abline(h=.8, col="red")

dev.off()


pdf(file = "C://Users/losen002/OneDrive - Universiteit Utrecht/Desktop/PhD/BayesianSSD/BF_PMP_H1_medium.pdf",   
    width = 6, # The width of the plot in inches
    height = 6) # The height of the plot in inches

  par(mfrow=c(2,4))
  plot(x=ss.seq, y=medbf10.H1[1:length(ss.seq)], type="l", xlab="N", ylab="median BF10 under H1")
  plot(x=ss.seq, y=medbf01.H1[1:length(ss.seq)], type="l", xlab="N", ylab="median BF01 under H1")
  plot(x=ss.seq, y=medbf.1u.H1[1:length(ss.seq)], type="l", xlab="N", ylab="median BF unconstr. under H1")
  plot(x=ss.seq, y=medbf.1c.H1[1:length(ss.seq)], type="l", xlab="N", ylab="median BF complement under H1")
  
  plot(x=ss.seq, y=medpmp.a1.H1[1:length(ss.seq)], type="l", xlab="N", ylab="median PMPa under H1")
  plot(x=ss.seq, y=medpmp.b1.H1[1:length(ss.seq)], type="l", xlab="N", ylab="median PMPb under H1")
  plot(x=ss.seq, y=medpmp.c1.H1[1:length(ss.seq)], type="l", xlab="N", ylab="median PMPc under H1")
  plot(x=ss.seq, y=prop.bf10.H1[1:length(ss.seq)], type="l", xlab="N", ylab="proportion of BFs larger 3 under H1")
  abline(h=eff.size, col="red")

dev.off()

```


The resulting Bayes Factors tell us that $H_1$ is the hypothesis most likely to be true out of the set of considered hypotheses. We therefore conclude that in the treatment group ($X_1$), the symptom level increases more over time compared to the control group ($X_0$).

## Descriptives/plots

```{r Descriptives, echo=F}
# plot individual trajectories
ggplot(data = dat, aes(x = t, y = y, group = id, color = as.factor(treat))) + geom_line()

boxplot(formula = y ~ treat, data = dat) # in a boxplot
```

As can be seen from the figure, individuals differ in their intercept and slope. Subjects in the treatment group ($X_1$) seem to have systematically higher slopes as compared to those in the control group ($X_0$), suggesting an interaction effect between time and treatment. Also, the variability of y scores seems to increase over time, rendering the assumption of compound symmetry untenable. 


```{r Plots, echo=F}
# one line for everyone
ggplot(data = dat, aes(x = t, y = y), color = treat) + 
  geom_jitter(aes(color = treat), width = .1, height = 0) + 
  geom_smooth(method = "lm", formula = 'y ~ x')
# base
p <- ggplot(data = dat, aes(x = t, y = y, group = id, color = treat)) + geom_jitter(width = .1, height = 0)
# different lines for treat
p  + geom_smooth(group = 0, method = "lm", data = subset(dat, dat$treat == 0), formula = 'y ~ x') + geom_smooth(group = 0, method = "lm", data = subset(dat, dat$treat == 1), formula = 'y ~ x')

```

## Intercept only model

```{r Intercept only}
int.only <- lmer(y ~ 1 + (1 | id), data = dat)
summary(int.only) 
logLik(int.only)           
performance::icc(int.only) 
p + geom_smooth(method = "lm", formula = y ~ 1, se = F)
```

--------------------------------------------------------------------------------

## Appendix: In-between models

### Level 1 predictor: time

```{r Lvl 1}
lvl1 <- lmer(y ~ time + (1 | id), data = dat)
summary(lvl1)
logLik(lvl1)           
anova(int.only, lvl1)  
performance::icc(lvl1) 
```


### Level 2 predictor: treat

```{r Lvl 2}
lvl2 <- lmer(y ~ time + treat + (1 | id), data = dat)
summary(lvl2)
logLik(lvl2)           # -1063.76 (df=5) - better fit compared to lvl1 predictor only
anova(lvl1, lvl2)      # likelihood ratio test significant
performance::icc(lvl2) # 0.044
vcov.lmerMod(lvl2)
```

### Random slope for time

```{r Random slope}
rand.slop <- lmer(y ~ time + treat + (1 + time | id), data = dat)
summary(rand.slop)
logLik(rand.slop) 
anova(lvl2, rand.slop)
performance::icc(rand.slop)
```
