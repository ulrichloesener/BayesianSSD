---
title: "Bayesian Sample Size Estimation for Multilevel Trials"
author: "Ulrich LÃ¶sener"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document: default
  pdf_document: default
---

# Simulation study for the project: Bayesian Sample Size Determination for Multilevel Trials

In this simulation study, I generate multilevel data for N individuals at n timepoints. The within variable is "time" and the between variable "treatment".

First, I call the necessary libraries.

```{r Packages, message=FALSE}
library(tidyr)       # pipes
library(dplyr)       # pipes
library(ggplot2)     # plots
library(nlme)
library(lme4)        # fit multilevel model
library(lmerTest)    # get p-values of multilevel model
library(conflicted)  # conflicting commands from different packages
library(merDeriv)    # extracting vcov matrices (vcov.lmerMod)
library(mgcv)        # extracting vcov matrices
library(bain)        # Bayesian estimation
library(MASS)        # multinorm - already included in lme4?

conflicts_prefer(lme4::lmer) # tell R to prefer lme4 over lmer
conflicts_prefer(dplyr::select)
```




```{r Data Generation}
N <- 100          # number of subjects
d <- c(0,1,2,3,4) # time of measurements
n <- length(d)    # number of measurements per subject

sigmasq.u0 <- 1  # variance of individual deviation from treatment intercept 
sigmasq.u1 <- 1  # variance of individual deviation from treatment slope
sigma.u0.u1 <- 0 # covariance between sigmasq.u0 and sigmasq.u1. If positive, then individuals with higher(lower) initial values tend to have a higher (lower) rate of change over time.
sigmasq.e <- 1 # error variance

# create data vectors
y <- rep(NA, N)  # data storage
t <- rep(d, N)
id <- rep(seq_len(N), each=n)
treat <- rep(c(0, 1), each=(N*n)/2)

beta0 <- rep(0, N*n) # average y at t0 for x=0
beta1 <- rep(1, N*n) # average increase for x=0
beta2 <- rep(.5, N*n) # average difference in slopes between conditions

#set.seed(123)      # for reproducibility

m <- 100           # number of datasets
sets <- vector("list", m)     # storage for datasets
est <- matrix(c(seq(1:m)), nrow = m, ncol = 2) # storage for fixed estimates
colnames(est) <- c("dataset", "t:treat")
bf12 <- numeric(m) # storage for BFs
bf.u <- numeric(m) # storage for BFs
bf.c <- numeric(m) # storage for BFs
pmp.b <- numeric(m) # storage for BFs

for (i in 1:m) {
multinorm <- mvrnorm(n=N,mu=c(0,0), matrix(c(sigmasq.u0, sigma.u0.u1, sigma.u0.u1, sigmasq.u1), nrow=2, ncol=2)) # draw individual deviation from treatment intercept and slope from a multivariate normal distribution with mean 0.
u0 <- rep(multinorm[,1], each=n)
u1 <- rep(multinorm[,2], each=n)
e <- rnorm(N*n, 0, sqrt(sigmasq.e))

y <- beta0 + u0 + beta1*t + beta2*treat*t + u1*t + e
dat <- data.frame(id, treat, t, y)
sets[[i]] <- dat

inter <- lme(y ~ t + t:treat, random =~ t - 1 | id, data = dat)
#, control = lmeControl(msMaxIter = 1000, msMaxEval = 1000))
est[i,2] <- inter$coefficients$fixed[3]
sig <- list(as.matrix(inter$varFix[3,3]))

result <- bain(est[i,2], hypotheses <- "t:treat>0;t:treat<0", n=N, Sigma = sig, group_parameters = 1)

bf12[i] <- result$BFmatrix[1,2]
bf.u[i] <- result$fit$BF.u[1]
bf.c[i] <- result$fit$BF.c[1]
pmp.b[i] <- result$fit$PMPb[1]

}

par(mfrow=c(2,2))
plot(sort(bf.u), type="l")
#plot(sort(bf.c), type="l")
plot(sort(bf12), type="l")

hist(bf.u)
#hist(bf.c)
hist(bf12)

#hist(pmp.b)
quantile(bf12, .20)

# check the bias in estimates of beta 2
mean(est[,2]- beta2) 

```

As can be seen from the figure, individuals differ in their intercept and slope. Subjects in the treatment group ($X_1$) seem to have systematically higher slopes as compared to those in the control group ($X_0$), suggesting an interaction effect between time and treatment. Also, the variability of y scores seems to increase over time, rendering the assumption of compound symmetry untenable. 


## Descriptives/plots

```{r Descriptives, echo=F}
# plot individual trajectories
ggplot(data = dat, aes(x = t, y = y, group = id, color = as.factor(treat))) + geom_line()

boxplot(formula = y ~ treat, data = dat) # in a boxplot
```

```{r Plots, echo=F}
# one line for everyone
ggplot(data = dat, aes(x = t, y = y), color = treat) + 
  geom_jitter(aes(color = treat), width = .1, height = 0) + 
  geom_smooth(method = "lm", formula = 'y ~ x')
# base
p <- ggplot(data = dat, aes(x = t, y = y, group = id, color = treat)) + geom_jitter(width = .1, height = 0)
# different lines for treat
p  + geom_smooth(group = 0, method = "lm", data = subset(dat, dat$treat == 0), formula = 'y ~ x') + geom_smooth(group = 0, method = "lm", data = subset(dat, dat$treat == 1), formula = 'y ~ x')

```


## Fit models

### Intercept only model

```{r Intercept only}
int.only <- lmer(y ~ 1 + (1 | id), data = dat)
summary(int.only) 
logLik(int.only)           
performance::icc(int.only) 
p + geom_smooth(method = "lm", formula = y ~ 1, se = F)
```

### Level 1 (time) and level 2 (treatment) predictors plus interaction between time and treatment

```{r Interaction effect}
inter <- lme(y ~ t + treat + t:treat, random =~ 1 + time | id, data = dat)
summary(inter)
```

### Bayesian hypothesis testing about the interaction coefficient

In this section, I test whether the treatment has an effect on the symptom trajectory over time. I formulate and test three competing hypotheses about the interaction coefficient $\beta_3$ against each other, their complements and the unconstrained hypothesis $H_u$ which does not postulate any constraints on the parameter. 

$$H_1: \beta_3 > 0 \\
H_1: \beta_3 < 0 \\
H_2: \beta_3 = 0 \\
H_u: \beta_3$$


```{r Bain}

est <- inter$coefficients$fixed
#covmat <- vcov.lmerMod(inter2)
#coef(inter)

sig <- list(as.matrix(inter$varFix[4,4]))

result <- bain(est[4], hypotheses <- "time:treat>0;time:treat<0;time:treat=0", n=N*n, Sigma = sig, group_parameters = 1)
result
```

The resulting Bayes Factors tell us that $H_1$ is the hypothesis most likely to be true out of the set of considered hypotheses. We therefore conclude that in the treatment group ($X_1$), the symptom level increases more over time compared to the control group ($X_0$).


--------------------------------------------------------------------------------

## Appendix: In-between models

### Level 1 predictor: time

```{r Lvl 1}
lvl1 <- lmer(y ~ time + (1 | id), data = dat)
summary(lvl1)
logLik(lvl1)           
anova(int.only, lvl1)  
performance::icc(lvl1) 
```


### Level 2 predictor: treat

```{r Lvl 2}
lvl2 <- lmer(y ~ time + treat + (1 | id), data = dat)
summary(lvl2)
logLik(lvl2)           # -1063.76 (df=5) - better fit compared to lvl1 predictor only
anova(lvl1, lvl2)      # likelihood ratio test significant
performance::icc(lvl2) # 0.044
vcov.lmerMod(lvl2)
```

### Random slope for time

```{r Random slope}
rand.slop <- lmer(y ~ time + treat + (1 + time | id), data = dat)
summary(rand.slop)
logLik(rand.slop) 
anova(lvl2, rand.slop)
performance::icc(rand.slop)
```
